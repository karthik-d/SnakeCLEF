{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import sklearn.metrics\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386006 70208\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"SnakeCLEF2021_train_metadata_PROD.csv\")\n",
    "min_train_metadata = pd.read_csv(\"SnakeCLEF2021_min-train_metadata_PROD.csv\")\n",
    "\n",
    "print(len(metadata), len(min_train_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binomial</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>genus</th>\n",
       "      <th>family</th>\n",
       "      <th>UUID</th>\n",
       "      <th>source</th>\n",
       "      <th>subset</th>\n",
       "      <th>class_id</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pantherophis spiloides</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Pantherophis</td>\n",
       "      <td>Colubridae</td>\n",
       "      <td>fbc816e9552643a2bce4f655b2f3c4e1</td>\n",
       "      <td>inaturalist</td>\n",
       "      <td>train</td>\n",
       "      <td>523</td>\n",
       "      <td>/Datasets/SnakeCLEF-2021/inaturalist/fbc816e95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Masticophis taeniatus</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Masticophis</td>\n",
       "      <td>Colubridae</td>\n",
       "      <td>cbc7ad7141a642f2b92ef7fe05c9d608</td>\n",
       "      <td>inaturalist</td>\n",
       "      <td>train</td>\n",
       "      <td>430</td>\n",
       "      <td>/Datasets/SnakeCLEF-2021/inaturalist/cbc7ad714...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crotalus pyrrhus</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Crotalus</td>\n",
       "      <td>Viperidae</td>\n",
       "      <td>fc4db72953ae4c978ac50acb33adce0c</td>\n",
       "      <td>inaturalist</td>\n",
       "      <td>train</td>\n",
       "      <td>183</td>\n",
       "      <td>/Datasets/SnakeCLEF-2021/inaturalist/fc4db7295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Haldea striatula</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Haldea</td>\n",
       "      <td>Colubridae</td>\n",
       "      <td>2068c79c956d43dc8a45106e0c808aed</td>\n",
       "      <td>inaturalist</td>\n",
       "      <td>train</td>\n",
       "      <td>305</td>\n",
       "      <td>/Datasets/SnakeCLEF-2021/inaturalist/2068c79c9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natrix natrix</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Natrix</td>\n",
       "      <td>Colubridae</td>\n",
       "      <td>3e376aaf4f8d42e991c0c8ddc5972f95</td>\n",
       "      <td>inaturalist</td>\n",
       "      <td>train</td>\n",
       "      <td>471</td>\n",
       "      <td>/Datasets/SnakeCLEF-2021/inaturalist/3e376aaf4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 binomial                   country      continent  \\\n",
       "0  Pantherophis spiloides  United States of America  North America   \n",
       "1   Masticophis taeniatus  United States of America  North America   \n",
       "2        Crotalus pyrrhus  United States of America  North America   \n",
       "3        Haldea striatula  United States of America  North America   \n",
       "4           Natrix natrix                    Russia         Europe   \n",
       "\n",
       "          genus      family                              UUID       source  \\\n",
       "0  Pantherophis  Colubridae  fbc816e9552643a2bce4f655b2f3c4e1  inaturalist   \n",
       "1   Masticophis  Colubridae  cbc7ad7141a642f2b92ef7fe05c9d608  inaturalist   \n",
       "2      Crotalus   Viperidae  fc4db72953ae4c978ac50acb33adce0c  inaturalist   \n",
       "3        Haldea  Colubridae  2068c79c956d43dc8a45106e0c808aed  inaturalist   \n",
       "4        Natrix  Colubridae  3e376aaf4f8d42e991c0c8ddc5972f95  inaturalist   \n",
       "\n",
       "  subset  class_id                                         image_path  \n",
       "0  train       523  /Datasets/SnakeCLEF-2021/inaturalist/fbc816e95...  \n",
       "1  train       430  /Datasets/SnakeCLEF-2021/inaturalist/cbc7ad714...  \n",
       "2  train       183  /Datasets/SnakeCLEF-2021/inaturalist/fc4db7295...  \n",
       "3  train       305  /Datasets/SnakeCLEF-2021/inaturalist/2068c79c9...  \n",
       "4  train       471  /Datasets/SnakeCLEF-2021/inaturalist/3e376aaf4...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70208 38601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metadata = min_train_metadata\n",
    "val_metadata = metadata[metadata['subset'] == 'val']\n",
    "\n",
    "print(len(train_metadata), len(val_metadata))\n",
    "len(min_train_metadata.binomial.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 772\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.df['image_path'].values[idx]\n",
    "        label = self.df['class_id'].values[idx]\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "model._fc = nn.Linear(model._fc.in_features, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "\n",
    "from albumentations import Compose, Normalize, Resize, HorizontalFlip, VerticalFlip\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import RandomCrop, HorizontalFlip, VerticalFlip, RandomBrightnessContrast, CenterCrop, PadIfNeeded, RandomResizedCrop\n",
    "\n",
    "def get_transforms(*, data):\n",
    "    assert data in ('train', 'valid')\n",
    "\n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            RandomResizedCrop(WIDTH, HEIGHT, scale=(0.8, 1.0)),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            RandomBrightnessContrast(p=0.2),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(WIDTH, HEIGHT),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(train_metadata, transform=get_transforms(data='train'))\n",
    "valid_dataset = TrainDataset(val_metadata, transform=get_transforms(data='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "WORKERS = 8\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:02,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1 - avg_train_loss: 5.0426  avg_val_loss: 3.7397 F1: 0.065554  Accuracy: 0.217274 time: 255s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:21,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2 - avg_train_loss: 3.6295  avg_val_loss: 3.1958 F1: 0.131081  Accuracy: 0.283361 time: 269s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:29,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3 - avg_train_loss: 3.1122  avg_val_loss: 3.0451 F1: 0.166816  Accuracy: 0.309111 time: 278s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:36,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4 - avg_train_loss: 2.7885  avg_val_loss: 2.8895 F1: 0.198979  Accuracy: 0.338566 time: 291s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550it [01:55,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5 - avg_train_loss: 2.5378  avg_val_loss: 2.8681 F1: 0.232379  Accuracy: 0.341546 time: 285s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:35,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 6 - avg_train_loss: 2.1108  avg_val_loss: 2.4461 F1: 0.298629  Accuracy: 0.425611 time: 284s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:39,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 7 - avg_train_loss: 2.0170  avg_val_loss: 2.4184 F1: 0.302618  Accuracy: 0.431077 time: 287s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:41,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 8 - avg_train_loss: 1.9617  avg_val_loss: 2.4027 F1: 0.309487  Accuracy: 0.432087 time: 295s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:39,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 9 - avg_train_loss: 1.9289  avg_val_loss: 2.3971 F1: 0.314581  Accuracy: 0.435792 time: 289s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:44,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10 - avg_train_loss: 1.8914  avg_val_loss: 2.3800 F1: 0.321931  Accuracy: 0.441051 time: 293s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:44,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 11 - avg_train_loss: 1.8325  avg_val_loss: 2.3572 F1: 0.326008  Accuracy: 0.444237 time: 299s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:38,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 12 - avg_train_loss: 1.8279  avg_val_loss: 2.3493 F1: 0.324886  Accuracy: 0.445817 time: 288s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:45,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 13 - avg_train_loss: 1.8217  avg_val_loss: 2.3567 F1: 0.326244  Accuracy: 0.444678 time: 294s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:41,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 14 - avg_train_loss: 1.8170  avg_val_loss: 2.3503 F1: 0.326443  Accuracy: 0.445921 time: 291s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:40,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15 - avg_train_loss: 1.8121  avg_val_loss: 2.3465 F1: 0.327316  Accuracy: 0.447165 time: 295s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:42,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 16 - avg_train_loss: 1.8058  avg_val_loss: 2.3502 F1: 0.325449  Accuracy: 0.446724 time: 291s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:43,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 17 - avg_train_loss: 1.8077  avg_val_loss: 2.3510 F1: 0.327032  Accuracy: 0.446465 time: 292s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:41,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 18 - avg_train_loss: 1.8109  avg_val_loss: 2.3489 F1: 0.326987  Accuracy: 0.446595 time: 290s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:44,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 19 - avg_train_loss: 1.8035  avg_val_loss: 2.3484 F1: 0.327835  Accuracy: 0.447009 time: 299s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:42,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 20 - avg_train_loss: 1.8024  avg_val_loss: 2.3443 F1: 0.328095  Accuracy: 0.447553 time: 291s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:42,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 21 - avg_train_loss: 1.8020  avg_val_loss: 2.3456 F1: 0.328408  Accuracy: 0.447812 time: 290s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:44,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 22 - avg_train_loss: 1.8093  avg_val_loss: 2.3476 F1: 0.328879  Accuracy: 0.447450 time: 296s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:36,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 23 - avg_train_loss: 1.8013  avg_val_loss: 2.3482 F1: 0.326461  Accuracy: 0.446517 time: 286s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:40,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 24 - avg_train_loss: 1.8021  avg_val_loss: 2.3468 F1: 0.327844  Accuracy: 0.447683 time: 289s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:39,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 25 - avg_train_loss: 1.8026  avg_val_loss: 2.3484 F1: 0.327776  Accuracy: 0.446983 time: 289s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:39,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 26 - avg_train_loss: 1.8059  avg_val_loss: 2.3476 F1: 0.327871  Accuracy: 0.447035 time: 295s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:36,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 27 - avg_train_loss: 1.8098  avg_val_loss: 2.3472 F1: 0.328543  Accuracy: 0.447709 time: 285s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:41,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 28 - avg_train_loss: 1.8032  avg_val_loss: 2.3512 F1: 0.327352  Accuracy: 0.445792 time: 290s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:41,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 29 - avg_train_loss: 1.8064  avg_val_loss: 2.3470 F1: 0.327592  Accuracy: 0.447035 time: 290s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:38,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 30 - avg_train_loss: 1.8023  avg_val_loss: 2.3472 F1: 0.326482  Accuracy: 0.447242 time: 293s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:37,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 31 - avg_train_loss: 1.8019  avg_val_loss: 2.3471 F1: 0.327138  Accuracy: 0.447268 time: 285s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:36,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 32 - avg_train_loss: 1.8041  avg_val_loss: 2.3468 F1: 0.328199  Accuracy: 0.447501 time: 285s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:37,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 33 - avg_train_loss: 1.8066  avg_val_loss: 2.3493 F1: 0.327517  Accuracy: 0.446595 time: 286s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:36,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 34 - avg_train_loss: 1.8048  avg_val_loss: 2.3482 F1: 0.328058  Accuracy: 0.446854 time: 288s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:37,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 35 - avg_train_loss: 1.8060  avg_val_loss: 2.3486 F1: 0.326996  Accuracy: 0.447294 time: 286s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:34,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 36 - avg_train_loss: 1.8068  avg_val_loss: 2.3474 F1: 0.327745  Accuracy: 0.446880 time: 284s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:33,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 37 - avg_train_loss: 1.8012  avg_val_loss: 2.3473 F1: 0.328329  Accuracy: 0.447165 time: 287s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:29,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 38 - avg_train_loss: 1.8051  avg_val_loss: 2.3523 F1: 0.327051  Accuracy: 0.445999 time: 279s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:38,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 39 - avg_train_loss: 1.8071  avg_val_loss: 2.3478 F1: 0.327381  Accuracy: 0.446569 time: 287s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:38,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 40 - avg_train_loss: 1.8015  avg_val_loss: 2.3475 F1: 0.328095  Accuracy: 0.447501 time: 287s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:37,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 41 - avg_train_loss: 1.8068  avg_val_loss: 2.3468 F1: 0.328143  Accuracy: 0.447165 time: 293s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:36,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 42 - avg_train_loss: 1.8002  avg_val_loss: 2.3453 F1: 0.328042  Accuracy: 0.447709 time: 285s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:32,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 43 - avg_train_loss: 1.8055  avg_val_loss: 2.3464 F1: 0.327669  Accuracy: 0.446906 time: 281s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:32,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 44 - avg_train_loss: 1.8077  avg_val_loss: 2.3452 F1: 0.328458  Accuracy: 0.447683 time: 281s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:37,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 45 - avg_train_loss: 1.8027  avg_val_loss: 2.3459 F1: 0.326877  Accuracy: 0.447113 time: 292s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:27,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 46 - avg_train_loss: 1.8028  avg_val_loss: 2.3508 F1: 0.326720  Accuracy: 0.446880 time: 276s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:32,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 47 - avg_train_loss: 1.8058  avg_val_loss: 2.3500 F1: 0.326431  Accuracy: 0.447139 time: 281s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:36,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 48 - avg_train_loss: 1.8010  avg_val_loss: 2.3456 F1: 0.327518  Accuracy: 0.447294 time: 285s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:35,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 49 - avg_train_loss: 1.8064  avg_val_loss: 2.3496 F1: 0.327641  Accuracy: 0.446310 time: 290s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1097it [03:36,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 50 - avg_train_loss: 1.8090  avg_val_loss: 2.3463 F1: 0.327178  Accuracy: 0.446543 time: 284s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import tqdm\n",
    "\n",
    "\n",
    "n_epochs = EPOCHS\n",
    "lr = 0.01\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, (images, labels) in tqdm.tqdm(enumerate(train_loader)):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        y_preds = model(images)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    avg_val_loss = 0.\n",
    "    preds = np.zeros((len(valid_dataset)))\n",
    "\n",
    "    for i, (images, labels) in enumerate(valid_loader):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "\n",
    "        preds[i * BATCH_SIZE: (i+1) * BATCH_SIZE] = y_preds.argmax(1).to('cpu').numpy()\n",
    "        loss = criterion(y_preds, labels)\n",
    "        avg_val_loss += loss.item() / len(valid_loader)\n",
    "        \n",
    "    scheduler.step()\n",
    "\n",
    "    score = f1_score(val_metadata['class_id'], preds, average='macro')\n",
    "    accuracy = accuracy_score(val_metadata['class_id'], preds)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f'  Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f} F1: {score:.6f}  Accuracy: {accuracy:.6f} time: {elapsed:.0f}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'SnakeCLEF2021-EfficientNet-B0_224-50E.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
